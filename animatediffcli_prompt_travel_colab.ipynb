{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepHansda/animatediff_cli_for_colab_adv/blob/main/animatediffcli_prompt_travel_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vljdVkbUnkID"
      },
      "source": [
        "\n",
        "### üéâ click the play button to run each cell. Left panel there is a folder that you can browse for files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2hhTdByIz5f"
      },
      "outputs": [],
      "source": [
        "!apt-get -qq install aria2\n",
        "from google.colab import drive\n",
        "import os, shutil, gc, time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWvax0gRo1M1"
      },
      "source": [
        "If you have any questions running it, feel free to check it out at the tutorial and reach out on [GitHub]. If you want to run it locally (needs a Nvidia or AMD GPU)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4KoSkrg1D-6"
      },
      "source": [
        "# AnimateDiff CLI SetUp.üõ†\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Set UP. ((It Will take some time ,Meanwhile can enjoy some coffie ‚òï  or Music üé∂.))"
      ],
      "metadata": {
        "id": "2DzQcdrR3Nau"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8eFw7zfJmoc"
      },
      "outputs": [],
      "source": [
        "# manually create a folder on your google drive. Need to connect it to make results persistent. click \"Allow\".\n",
        "# it will ask you for permission.\n",
        "# create a folder called \"AnimateDiffPromptTravel\" in it\n",
        "gd_output_dir=\"\"\n",
        "base_path = \"/content/animatediff-cli-prompt-travel\"\n",
        "pwd = %pwd\n",
        "print(pwd)\n",
        "if pwd != base_path:\n",
        "  !git clone https://github.com/s9roll7/animatediff-cli-prompt-travel\n",
        "  %cd {base_path}\n",
        "\n",
        "  !pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118\n",
        "  !pip install .[dev]\n",
        "  !pip install xformers mediapipe\n",
        "  !pip install onnxruntime-gpu pandas\n",
        "\n",
        "\n",
        "\n",
        "#connect drive\n",
        "# manually create a folder on your google drive. Need to connect it to make results persistent. click \"Allow\".\n",
        "def connect_drive():\n",
        "  drive.mount(\"GoogleDrive\")\n",
        "  gd_path = \"GoogleDrive/MyDrive/AnimateDiffPromptTravel\"\n",
        "  gd_output_dir = gd_path + \"/output\"\n",
        "  os.makedirs(gd_output_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTBDiNb71s6h"
      },
      "source": [
        "##Connect Google Drive ((Optional)).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "br1IjxE3z-0D"
      },
      "outputs": [],
      "source": [
        "  #connect drive\n",
        "  # manually create a folder on your google drive. Need to connect it to make results persistent. click \"Allow\".\n",
        "  # it will ask you for permission.\n",
        "  # create a folder called \"AnimateDiffPromptTravel\" in it\n",
        "\n",
        "connect_drive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFUu2Jh1EkmT"
      },
      "outputs": [],
      "source": [
        "!gdown --id 1tXQOZDHHxeIHvsqnsuwdrFBXjHCh7Gle -O /content/animatediff-cli-prompt-travel/GoogleDrive/MyDrive/AnimateDiffPromptTravel/pahari.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-tBLhZm2uXw"
      },
      "source": [
        "#Download AI üóø MODELS üöÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Download AnimateDiff Motion Modules.‚ú®"
      ],
      "metadata": {
        "id": "yWzyfX735p-4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "g_Z5Mzc_JmvR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96518e37-ac03-444b-dcf5-f7db678debdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\n",
            "Download Results:\n",
            "gid   |stat|avg speed  |path/URI\n",
            "======+====+===========+=======================================================\n",
            "9abddd|\u001b[1;32mOK\u001b[0m  |   176MiB/s|/content/animatediff-cli-prompt-travel/data/models/motion-module/temporaldiff-v1-animatediff.ckpt\n",
            "\n",
            "Status Legend:\n",
            "(OK):download completed.\n"
          ]
        }
      ],
      "source": [
        "# AnimateDiff MotionModule download......................................\n",
        "#Remove the hashtag for desired modules. !------------\n",
        "\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/178017 -d /content/animatediff-cli-prompt-travel/data/models/motion-module -o improved3DMotion_improved3DV1.ckpt\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/guoyww/animatediff/resolve/main/mm_sd_v15_v2.ckpt?download=true -d /content/animatediff-cli-prompt-travel/data/models/motion-module -o mm_sd_v15_v2.ckpt\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/manshoety/AD_Stabilized_Motion/resolve/main/mm-Stabilized_high.pth?download=true -d /content/animatediff-cli-prompt-travel/data/models/motion-module -o mm-Stabilized_high.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/CiaraRowles/TemporalDiff/resolve/main/temporaldiff-v1-animatediff.ckpt?download=true -d /content/animatediff-cli-prompt-travel/data/models/motion-module -o temporaldiff-v1-animatediff.ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me2gDmsf2wHw"
      },
      "source": [
        "## Download Stable Diffusion Model ‚öô (SD v1.5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0XepFH4Jmx9"
      },
      "outputs": [],
      "source": [
        "# SD model download  SD 1.5\n",
        "# feel free to experiment other models\n",
        "#Remove the hashtag for desired checkpoints. !------------\n",
        "\n",
        "#Realistic checkpoints:\n",
        "#!curl -Lo \"/content/animatediff-cli-prompt-travel/data/models/sd/Epicrealismv5.safetensors\" \"https://civitai.com/api/download/models/134065?type=Model&format=SafeTensor&size=pruned&fp=fp16\"\n",
        "#!curl -Lo \"/content/animatediff-cli-prompt-travel/data/models/sd/Cyberrealistic.safetensors\" \"https://civitai.com/api/download/models/138176?type=Model&format=SafeTensor&size=pruned&fp=fp16\"\n",
        "# !curl -Lo \"/content/animatediff-cli-prompt-travel/data/models/sd/Majicmix.safetensors\" \"https://civitai.com/api/download/models/94640\"\n",
        "#!curl -Lo \"/content/animatediff-cli-prompt-travel/data/models/sd/Photon.safetensors\" \"https://civitai.com/api/download/models/90072\"\n",
        "#!curl -Lo \"/content/animatediff-cli-prompt-travel/data/models/sd/chilloutmix.safetensors\" \"https://civitai.com/api/download/models/11745\"\n",
        "#!curl -Lo \"/content/animatediff-cli-prompt-travel/data/models/sd/DreamShaper_8_pruned.safetensors\" \"https://huggingface.co/Lykon/DreamShaper/resolve/main/DreamShaper_8_pruned.safetensors?download=true\"\n",
        "#!curl -Lo \"/content/animatediff-cli-prompt-travel/data/models/sd/ProtoGen_X5.8-pruned-fp16.safetensors\" \"https://huggingface.co/darkstorm2150/Protogen_x5.8_Official_Release/resolve/main/ProtoGen_X5.8-pruned-fp16.safetensors?download=true\"\n",
        "#!curl -Lo \"/content/animatediff-cli-prompt-travel/data/models/sd/Dreamlike_Diffusion_1.safetensors\" \"https://civitai.com/api/download/models/1356\"\n",
        "\n",
        "#Animation checkpoints:\n",
        "# !curl -Lo \"/content/animatediff-cli-prompt-travel/data/models/sd/RealCartoon-Pixar.ckpt\" \"https://huggingface.co/jzli/RealCartoon-Pixar-V5/resolve/main/realcartoonPixar_v5.ckpt?download=true\"\n",
        "!curl -Lo \"/content/animatediff-cli-prompt-travel/data/models/sd/toonyou_beta6.safetensors\" \"https://huggingface.co/frankjoshua/toonyou_beta6/resolve/main/toonyou_beta6.safetensors?download=true\"\n",
        "#Anime checkpoints:\n",
        "!wget -c https://civitai.com/api/download/models/98960 -O /content/animatediff-cli-prompt-travel/data/models/sd/toonyou-jp.safetensors\n",
        "# !curl -Lo \"/content/animatediff-cli-prompt-travel/data/models/sd/Anything_V4_5.safetensors\" \"https://civitai.com/api/download/models/5581\"\n",
        "# !curl -Lo \"/content/animatediff-cli-prompt-travel/data/models/sd/Anything_V5.safetensors\" \"https://civitai.com/api/download/models/30163\"\n",
        "#!curl -Lo \"/content/animatediff-cli-prompt-travel/data/models/sd/DivineEleganceMix_V6\" \"https://civitai.com/api/download/models/122702\"\n",
        "#!curl -Lo \"/content/animatediff-cli-prompt-travel/data/models/sd/AnimeCreative\" \"https://civitai.com/api/download/models/163570\"\n",
        "#!curl -Lo \"/content/animatediff-cli-prompt-travel/data/models/sd/Counterfeit_V3\" \"https://civitai.com/api/download/models/57618\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -P /content/animatediff-cli-prompt-travel/data/models/vae"
      ],
      "metadata": {
        "id": "l1kjONjW2Wn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXgV9FtA81-J"
      },
      "source": [
        "# CLI Prompts ((Important!)) üìÉ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh2DnIGUHnaK"
      },
      "source": [
        "Check keyframes in Prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HWwV6SkEXYe",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#check keyframes in prompts\n",
        "fps = 15 # @param {type:\"number\"}\n",
        "duration_in_sec = 18 # @param {type:\"number\"}\n",
        "for x in range(0,duration_in_sec+1):\n",
        "  # x=x+2\n",
        "  print(x*fps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVvJwnXl-dS0"
      },
      "source": [
        "## One For All Prompt Template.(Also a Doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH2-DIttmVLR"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# test sample config file ### to make updates to the config file (open it and modify. See the youtube video for details!)\n",
        "# template in: animatediff-cli-prompt-travel/config/prompts/prompt_travel.json\n",
        "config_sample_txt = \"\"\"\n",
        "\n",
        "{\n",
        "  \"name\": \"sample\",\n",
        "  \"path\": \"share/Stable-diffusion/mistoonAnime_v20.safetensors\",  # Specify Checkpoint as a path relative to /animatediff-cli/data\n",
        "  \"lcm_map\":{     # lcm-lora\n",
        "    \"enable\":false,\n",
        "    \"start_scale\":0.15,\n",
        "    \"end_scale\":0.75,\n",
        "    \"gradient_start\":0.2,\n",
        "    \"gradient_end\":0.75\n",
        "  },\n",
        "  \"gradual_latent_hires_fix_map\":{ # gradual latent hires fix\n",
        "    # This is an option to address the problem of chaos being generated when the model is generated beyond its proper size.\n",
        "    # It also has the effect of increasing generation speed.\n",
        "    \"enable\": false,    # enable/disable\n",
        "    \"scale\": {    # \"DENOISE PROGRESS\" : LATENT SCALE format\n",
        "      # In this example, Up to 70% of the total denoise, latent is halved to the specified size.\n",
        "      # From 70% to the end, calculate the size as specified.\n",
        "      \"0\": 0.5,\n",
        "      \"0.7\": 1.0\n",
        "    },\n",
        "    \"reverse_steps\": 5,          # Number of reversal steps at latent size switching timing\n",
        "    \"noise_add_count\":3          # Additive amount of noise„ÄÄat latent size switching timing\n",
        "  },\n",
        "  \"vae_path\":\"share/VAE/vae-ft-mse-840000-ema-pruned.ckpt\",       # Specify vae as a path relative to /animatediff-cli/data\n",
        "  \"motion_module\": \"models/motion-module/mm_sd_v14.ckpt\",         # Specify motion module as a path relative to /animatediff-cli/data\n",
        "  \"context_schedule\":\"uniform\",          # \"uniform\" or \"composite\"\n",
        "  \"compile\": false,\n",
        "  \"seed\": [\n",
        "    341774366206100,-1,-1         # -1 means random. If \"--repeats 3\" is specified in this setting, The first will be 341774366206100, the second and third will be random.\n",
        "  ],\n",
        "  \"scheduler\": \"ddim\",      # \"ddim\",\"euler\",\"euler_a\",\"k_dpmpp_2m\", etc...\n",
        "  \"steps\": 40,\n",
        "  \"guidance_scale\": 20,     # cfg scale\n",
        "  \"clip_skip\": 2,\n",
        "  \"prompt_fixed_ratio\": 0.5,\n",
        "  \"head_prompt\": \"masterpiece, best quality, a beautiful and detailed portriat of muffet, monster girl,((purple body:1.3)),humanoid, arachnid, anthro,((fangs)),pigtails,hair bows,5 eyes,spider girl,6 arms,solo\",\n",
        "  \"prompt_map\": {           # \"FRAME\" : \"PROMPT\" format / ex. prompt for frame 32 is \"head_prompt\" + prompt_map[\"32\"] + \"tail_prompt\"\n",
        "    \"0\":  \"smile standing,((spider webs:1.0))\",\n",
        "    \"32\":  \"(((walking))),((spider webs:1.0))\",\n",
        "    \"64\":  \"(((running))),((spider webs:2.0)),wide angle lens, fish eye effect\",\n",
        "    \"96\":  \"(((sitting))),((spider webs:1.0))\"\n",
        "  },\n",
        "  \"tail_prompt\": \"clothed, open mouth, awesome and detailed background, holding teapot, holding teacup, 6 hands,detailed hands,storefront that sells pastries and tea,bloomers,(red and black clothing),inside,pouring into teacup,muffetwear\",\n",
        "  \"n_prompt\": [\n",
        "    \"(worst quality, low quality:1.4),nudity,simple background,border,mouth closed,text, patreon,bed,bedroom,white background,((monochrome)),sketch,(pink body:1.4),7 arms,8 arms,4 arms\"\n",
        "  ],\n",
        "  \"lora_map\": {             # \"PATH_TO_LORA\" : STRENGTH format\n",
        "    \"share/Lora/muffet_v2.safetensors\" : 1.0,                     # Specify lora as a path relative to /animatediff-cli/data\n",
        "    \"share/Lora/add_detail.safetensors\" : 1.0                     # Lora support is limited. Not all formats can be used!!!\n",
        "  },\n",
        "  \"motion_lora_map\": {      # \"PATH_TO_LORA\" : STRENGTH format\n",
        "    \"models/motion_lora/v2_lora_RollingAnticlockwise.ckpt\":0.5,   # Currently, the officially distributed lora seems to work only for v2 motion modules (mm_sd_v15_v2.ckpt).\n",
        "    \"models/motion_lora/v2_lora_ZoomIn.ckpt\":0.5\n",
        "  },\n",
        "  \"ip_adapter_map\": {       # config for ip-adapter\n",
        "      # enable/disable (important)\n",
        "      \"enable\": true,\n",
        "      # Specify input image directory relative to /animatediff-cli/data (important! No need to specify frames in the config file. The effect on generation is exactly the same logic as the placement of the prompt)\n",
        "      \"input_image_dir\": \"ip_adapter_image/test\",\n",
        "      \"prompt_fixed_ratio\": 0.5,\n",
        "      # save input image or not\n",
        "      \"save_input_image\": true,\n",
        "      # Ratio of image prompt vs text prompt (important). Even if you want to emphasize only the image prompt in 1.0, do not leave prompt/neg prompt empty, but specify a general text such as \"best quality\".\n",
        "      \"scale\": 0.5,\n",
        "      # IP-Adapter/IP-Adapter Full Face/IP-Adapter Plus Face/IP-Adapter Plus/IP-Adapter Light (important) It would be a completely different outcome. Not always PLUS a superior result.\n",
        "      \"is_full_face\": false,\n",
        "      \"is_plus_face\": false,\n",
        "      \"is_plus\": true,\n",
        "      \"is_light\": false\n",
        "  },\n",
        "  \"img2img_map\": {\n",
        "      # enable/disable\n",
        "      \"enable\": true,\n",
        "      # Directory where the initial image is placed\n",
        "      \"init_img_dir\": \"..\\\\stylize\\\\2023-10-27T19-43-01-sample-mistoonanime_v20\\\\00_img2img\",\n",
        "      \"save_init_image\": true,\n",
        "      # The smaller the value, the closer the result will be to the initial image.\n",
        "      \"denoising_strength\": 0.7\n",
        "  },\n",
        "  \"region_map\": {\n",
        "      # setting for region 0. You can also add regions if necessary.\n",
        "      # The region added at the back will be drawn at the front.\n",
        "      \"0\": {\n",
        "          # enable/disable\n",
        "          \"enable\": true,\n",
        "          # If you want to draw a separate object for each region, enter a value of 0.1 or higher.\n",
        "          \"crop_generation_rate\": 0.1,\n",
        "          # Directory where mask images are placed\n",
        "          \"mask_dir\": \"..\\\\stylize\\\\2023-10-27T19-43-01-sample-mistoonanime_v20\\\\r_fg_00_2023-10-27T19-44-08\\\\00_mask\",\n",
        "          \"save_mask\": true,\n",
        "          # If true, the initial image will be drawn as is (inpaint)\n",
        "          \"is_init_img\": false,\n",
        "          # conditions for region 0\n",
        "          \"condition\": {\n",
        "              # text prompt for region 0\n",
        "              \"prompt_fixed_ratio\": 0.5,\n",
        "              \"head_prompt\": \"\",\n",
        "              \"prompt_map\": {\n",
        "                  \"0\": \"(masterpiece, best quality:1.2), solo, 1girl, kusanagi motoko, looking at viewer, jacket, leotard, thighhighs, gloves, cleavage\"\n",
        "               },\n",
        "              \"tail_prompt\": \"\",\n",
        "              # image prompt(ip adapter) for region 0\n",
        "              # It is not possible to change lora for each region, but you can do something similar using an ip adapter.\n",
        "              \"ip_adapter_map\": {\n",
        "                  \"enable\": true,\n",
        "                  \"input_image_dir\": \"..\\\\stylize\\\\2023-10-27T19-43-01-sample-mistoonanime_v20\\\\r_fg_00_2023-10-27T19-44-08\\\\00_ipadapter\",\n",
        "                  \"prompt_fixed_ratio\": 0.5,\n",
        "                  \"save_input_image\": true,\n",
        "                  \"resized_to_square\": false\n",
        "              }\n",
        "          }\n",
        "      },\n",
        "      # setting for background\n",
        "      \"background\": {\n",
        "          # If true, the initial image will be drawn as is (inpaint)\n",
        "          \"is_init_img\": true,\n",
        "          \"hint\": \"background's condition refers to the one in root\"\n",
        "      }\n",
        "  },\n",
        "  \"controlnet_map\": {       # config for controlnet(for generation)\n",
        "    \"input_image_dir\" : \"controlnet_image/test\",    # Specify input image directory relative to /animatediff-cli/data (important! Please refer to the directory structure of sample. No need to specify frames in the config file.)\n",
        "    \"max_samples_on_vram\" : 200,    # If you specify a large number of images for controlnet and vram will not be enough, reduce this value. 0 means that everything should be placed in cpu.\n",
        "    \"max_models_on_vram\" : 3,       # Number of controlnet models to be placed in vram\n",
        "    \"save_detectmap\" : true,        # save preprocessed image or not\n",
        "    \"preprocess_on_gpu\": true,      # run preprocess on gpu or not (It probably does not affect vram usage at peak, so it should always set true.)\n",
        "    \"is_loop\": true,                # Whether controlnet effects consider loop\n",
        "\n",
        "    \"controlnet_tile\":{    # config for controlnet_tile\n",
        "      \"enable\": true,              # enable/disable (important)\n",
        "      \"use_preprocessor\":true,      # Whether to use a preprocessor for each controlnet type\n",
        "      \"preprocessor\":{     # If not specified, the default preprocessor is selected.(Most of the time the default should be fine.)\n",
        "        # none/blur/tile_resample/upernet_seg/ or key in controlnet_aux.processor.MODELS\n",
        "        # https://github.com/patrickvonplaten/controlnet_aux/blob/2fd027162e7aef8c18d0a9b5a344727d37f4f13d/src/controlnet_aux/processor.py#L20\n",
        "        \"type\" : \"tile_resample\",\n",
        "        \"param\":{\n",
        "          \"down_sampling_rate\":2.0\n",
        "        }\n",
        "      },\n",
        "      \"guess_mode\":false,\n",
        "      # control weight (important)\n",
        "      \"controlnet_conditioning_scale\": 1.0,\n",
        "      # starting control step\n",
        "      \"control_guidance_start\": 0.0,\n",
        "      # ending control step\n",
        "      \"control_guidance_end\": 1.0,\n",
        "      # list of influences on neighboring frames (important)\n",
        "      # This means that there is an impact of 0.5 on both neighboring frames and 0.4 on the one next to it. Try lengthening, shortening, or changing the values inside.\n",
        "      \"control_scale_list\":[0.5,0.4,0.3,0.2,0.1],\n",
        "      # list of regions where controlnet works\n",
        "      # In this example, it only affects region \"0\", but not \"background\".\n",
        "      \"control_region_list\": [\"0\"]\n",
        "    },\n",
        "    \"controlnet_ip2p\":{\n",
        "      \"enable\": true,\n",
        "      \"use_preprocessor\":true,\n",
        "      \"guess_mode\":false,\n",
        "      \"controlnet_conditioning_scale\": 1.0,\n",
        "      \"control_guidance_start\": 0.0,\n",
        "      \"control_guidance_end\": 1.0,\n",
        "      \"control_scale_list\":[0.5,0.4,0.3,0.2,0.1],\n",
        "      # In this example, all regions are affected\n",
        "      \"control_region_list\": []\n",
        "    },\n",
        "    \"controlnet_lineart_anime\":{\n",
        "      \"enable\": true,\n",
        "      \"use_preprocessor\":true,\n",
        "      \"guess_mode\":false,\n",
        "      \"controlnet_conditioning_scale\": 1.0,\n",
        "      \"control_guidance_start\": 0.0,\n",
        "      \"control_guidance_end\": 1.0,\n",
        "      \"control_scale_list\":[0.5,0.4,0.3,0.2,0.1],\n",
        "      # In this example, it only affects region \"background\", but not \"0\".\n",
        "      \"control_region_list\": [\"background\"]\n",
        "    },\n",
        "    \"controlnet_openpose\":{\n",
        "      \"enable\": true,\n",
        "      \"use_preprocessor\":true,\n",
        "      \"guess_mode\":false,\n",
        "      \"controlnet_conditioning_scale\": 1.0,\n",
        "      \"control_guidance_start\": 0.0,\n",
        "      \"control_guidance_end\": 1.0,\n",
        "      \"control_scale_list\":[0.5,0.4,0.3,0.2,0.1],\n",
        "      # In this example, all regions are affected (since these are the only two regions defined)\n",
        "      \"control_region_list\": [\"0\", \"background\"]\n",
        "    },\n",
        "    \"controlnet_softedge\":{\n",
        "      \"enable\": true,\n",
        "      \"use_preprocessor\":true,\n",
        "      \"preprocessor\":{\n",
        "        \"type\" : \"softedge_pidsafe\",\n",
        "        \"param\":{\n",
        "        }\n",
        "      },\n",
        "      \"guess_mode\":false,\n",
        "      \"controlnet_conditioning_scale\": 1.0,\n",
        "      \"control_guidance_start\": 0.0,\n",
        "      \"control_guidance_end\": 1.0,\n",
        "      \"control_scale_list\":[0.5,0.4,0.3,0.2,0.1]\n",
        "    },\n",
        "    \"controlnet_ref\": {\n",
        "        \"enable\": false,            # enable/disable (important)\n",
        "        \"ref_image\": \"ref_image/ref_sample.png\",     # path to reference image.\n",
        "        \"attention_auto_machine_weight\": 1.0,\n",
        "        \"gn_auto_machine_weight\": 1.0,\n",
        "        \"style_fidelity\": 0.5,                # control weight-like parameter(important)\n",
        "        \"reference_attn\": true,               # [attn=true , adain=false] means \"reference_only\"\n",
        "        \"reference_adain\": false,\n",
        "        \"scale_pattern\":[0.5]                 # Pattern for applying controlnet_ref to frames\n",
        "    }                                         # ex. [0.5] means [0.5,0.5,0.5,0.5,0.5 .... ]. All frames are affected by 50%\n",
        "                                              # ex. [1, 0] means [1,0,1,0,1,0,1,0,1,0,1 ....]. Only even frames are affected by 100%.\n",
        "  },\n",
        "  \"upscale_config\": {       # config for tile-upscale\n",
        "    \"scheduler\": \"ddim\",\n",
        "    \"steps\": 20,\n",
        "    \"strength\": 0.5,\n",
        "    \"guidance_scale\": 10,\n",
        "    \"controlnet_tile\": {    # config for controlnet tile\n",
        "      \"enable\": true,       # enable/disable (important)\n",
        "      \"controlnet_conditioning_scale\": 1.0,     # control weight (important)\n",
        "      \"guess_mode\": false,\n",
        "      \"control_guidance_start\": 0.0,      # starting control step\n",
        "      \"control_guidance_end\": 1.0         # ending control step\n",
        "    },\n",
        "    \"controlnet_line_anime\": {  # config for controlnet line anime\n",
        "      \"enable\": false,\n",
        "      \"controlnet_conditioning_scale\": 1.0,\n",
        "      \"guess_mode\": false,\n",
        "      \"control_guidance_start\": 0.0,\n",
        "      \"control_guidance_end\": 1.0\n",
        "    },\n",
        "    \"controlnet_ip2p\": {  # config for controlnet ip2p\n",
        "      \"enable\": false,\n",
        "      \"controlnet_conditioning_scale\": 0.5,\n",
        "      \"guess_mode\": false,\n",
        "      \"control_guidance_start\": 0.0,\n",
        "      \"control_guidance_end\": 1.0\n",
        "    },\n",
        "    \"controlnet_ref\": {   # config for controlnet ref\n",
        "      \"enable\": false,             # enable/disable (important)\n",
        "      \"use_frame_as_ref_image\": false,   # use original frames as ref_image for each upscale (important)\n",
        "      \"use_1st_frame_as_ref_image\": false,   # use 1st original frame as ref_image for all upscale (important)\n",
        "      \"ref_image\": \"ref_image/path_to_your_ref_img.jpg\",   # use specified image file as ref_image for all upscale (important)\n",
        "      \"attention_auto_machine_weight\": 1.0,\n",
        "      \"gn_auto_machine_weight\": 1.0,\n",
        "      \"style_fidelity\": 0.25,       # control weight-like parameter(important)\n",
        "      \"reference_attn\": true,       # [attn=true , adain=false] means \"reference_only\"\n",
        "      \"reference_adain\": false\n",
        "    }\n",
        "  },\n",
        "  \"output\":{   # output format\n",
        "    \"format\" : \"gif\",   # gif/mp4/webm\n",
        "    \"fps\" : 8,\n",
        "    \"encode_param\":{\n",
        "      \"crf\": 10\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "config_file_path = f\"config/prompts/test001.json\"\n",
        "with open(config_file_path, \"w\") as file:\n",
        "    file.write(config_sample_txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIQ6TrKa9w3S"
      },
      "source": [
        "##**Hires Fix Prompt Template.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QJywSP69nwM"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# test sample config file ### to make updates to the config file (open it and modify. See the youtube video for details!)\n",
        "# template in: animatediff-cli-prompt-travel/config/prompts/prompt_travel.json\n",
        "config_sample_txt = \"\"\"\n",
        "{\n",
        "    \"name\": \"simple\",\n",
        "    \"path\": \"models/sd/toonyou-jp.safetensors\",\n",
        "    \"vae_path\": \"\",\n",
        "    \"motion_module\": \"models/motion-module/improved3DMotion_improved3DV1.ckpt\",\n",
        "    \"gradual_latent_hires_fix_map\": {\n",
        "        \"enable\": true,\n",
        "        \"scale\": {\n",
        "            \"0\": 0.5,\n",
        "            \"0.7\": 1.0\n",
        "        },\n",
        "        \"reverse_steps\": 5,\n",
        "        \"noise_add_count\": 3\n",
        "    },\n",
        "    \"compile\": false,\n",
        "    \"seed\": [\n",
        "       -1\n",
        "    ],\n",
        "    \"scheduler\": \"euler_a\",\n",
        "    \"steps\": 25,\n",
        "    \"guidance_scale\": 8.5,\n",
        "    \"clip_skip\": 2,\n",
        "    \"prompt_map\": {\n",
        "        \"0\": \"(masterpiece, best quality,zoom_in, looking at viewers ), 1girl,cute, upper body, paw pose,  happy, ocean, crop top, shorts, blonde,airflow, blush, looking at viewer, wavy hair, long hair, cloud, sun, mountain, wet, high contrast colors \",\n",
        "        \"24\": \"(masterpiece, best quality,from_side_left), 1girl,cute, upper body, paw pose, smile, laughing, happy, ocean, crop top, shorts, blonde, airflow , blush, wavy hair, long hair, cloud, sun, mountain, wet, high contrast colors\",\n",
        "        \"48\": \"(masterpiece, best quality,from_side_right, laughs ), 1girl,cute, upper body, paw pose, smile, laughing, happy, ocean, crop top, shorts, blonde, airflow, blush, looking at viewer, wavy hair, long hair, sun, mountain, wet, high contrast colors\"\n",
        "    },\n",
        "    \"n_prompt\": [\n",
        "        \"out of frame,jpeg artifacts, (signature), watermark, username, artist name, (worst quality, low quality), bad anatomy, worst quality, normal quality, low quality, low res, blurry, text, watermark, logo, banner, extra digits, cropped, jpeg artifacts, signature, \"\n",
        "    ],\n",
        "    \"lora_map\": {\n",
        "\n",
        "    },\n",
        "    \"motion_lora_map\": {},\n",
        "    \"stylize_config\": {},\n",
        "    \"output\": {\n",
        "        \"format\": \"mp4\",\n",
        "        \"fps\": 10,\n",
        "        \"encode_param\": {\n",
        "            \"crf\": 10\n",
        "        }\n",
        "    },\n",
        "    \"result\": {}\n",
        "}\n",
        "\"\"\"\n",
        "config_file_path = f\"config/prompts/test001.json\"\n",
        "with open(config_file_path, \"w\") as file:\n",
        "    file.write(config_sample_txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwd8ec1C-gvi"
      },
      "source": [
        "# Generate ‚öô"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff1JmYdNFiO8"
      },
      "outputs": [],
      "source": [
        "#check help for better understanding.........\n",
        "!animatediff generate -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxsrSruoJm0b",
        "outputId": "2f98db6d-3e9a-4b9b-b960-cb318552f235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-08 03:30:30.018227: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-08 03:30:30.018293: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-08 03:30:30.027776: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-08 03:30:32.734425: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_5m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_11m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_384 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_512 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  return register_model(fn_wrapper)\n",
            "diffuser_ver='0.23.0'\n",
            "Using generation config: config/prompts/prompt_girl.json\n",
            "is_sdxl=False\n",
            "is_v2=False\n",
            "Using base model: runwayml/stable-diffusion-v1-5\n",
            "Will save outputs to ./output/2024-01-08T03-30-49-sample-toonyou-jp\n",
            "\u001b[2KPreprocessing images (controlnet_ip2p)\u001b[35m   7%\u001b[0m \u001b[91m‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18/251 \u001b[0m [ \u001b[33m0:00:01\u001b[0m < \u001b[36m0:00:15\u001b[0m , \u001b[31m17 it/s\u001b[0m ]\n",
            "\u001b[2KSaving Preprocessed images (controlnet_ip2p)\u001b[35m  95%\u001b[0m \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m \u001b[32m18/19 \u001b[0m [ \u001b[33m0:00:01\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m13 it/s\u001b[0m ]\n",
            "\u001b[2KPreprocessing images (controlnet_openpose)\u001b[35m   0%\u001b[0m \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0/251 \u001b[0m [ \u001b[33m0:00:00\u001b[0m < \u001b[36m-:--:--\u001b[0m , \u001b[31m? it/s\u001b[0m ]2024-01-08 03:30:53.656118899 [E:onnxruntime:Default, provider_bridge_ort.cc:1480 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1193 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\n",
            "2024-01-08 03:30:53.656160776 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:747 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Please reference https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements to ensure all dependencies are met.\n",
            "\u001b[2KPreprocessing images (controlnet_openpose)\u001b[35m   0%\u001b[0m \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0/251 \u001b[0m [ \u001b[33m0:00:01\u001b[0m < \u001b[36m-:--:--\u001b[0m , \u001b[31m? it/s\u001b[0m ]2024-01-08 03:30:54.969192507 [E:onnxruntime:Default, provider_bridge_ort.cc:1480 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1193 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "\n",
            "2024-01-08 03:30:54.969229626 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:747 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Please reference https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements to ensure all dependencies are met.\n",
            "\u001b[2KPreprocessing images (controlnet_openpose)\u001b[35m   8%\u001b[0m \u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19/251 \u001b[0m [ \u001b[33m0:01:02\u001b[0m < \u001b[36m0:12:13\u001b[0m , \u001b[31m0 it/s\u001b[0m ]\n",
            "\u001b[2KSaving Preprocessed images (controlnet_openpose)\u001b[35m  79%\u001b[0m \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ\u001b[0m \u001b[32m15/19 \u001b[0m [ \u001b[33m0:00:00\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m71 it/s\u001b[0m ]\n",
            "\u001b[?25hChecking motion module...\n",
            "Loading tokenizer...\n",
            "Loading text encoder...\n",
            "Loading VAE...\n",
            "Loading UNet...\n",
            "Loaded 417.1376M-parameter motion module\n",
            "Using scheduler \"euler_a\" (EulerAncestralDiscreteScheduler)\n",
            "Loading weights from /content/animatediff-cli-prompt-travel/data/models/sd/toonyou-jp.safetensors\n",
            "Merging weights into UNet...\n",
            "Loading vae from /content/animatediff-cli-prompt-travel/data/models/vae/vae-ft-mse-840000-ema-pruned.safetensors\n",
            "Creating AnimationPipeline...\n",
            "No TI embeddings found\n",
            "loading c='controlnet_ip2p' model\n",
            "loading c='controlnet_openpose' model\n",
            "Sending pipeline to device \"cuda\"\n",
            "Selected data types: unet_dtype=torch.float16, tenc_dtype=torch.float16, vae_dtype=torch.float32\n",
            "Using channels_last memory format for UNet and VAE\n",
            "\u001b[2KPreprocessing images (ip_adapter)\u001b[35m   0%\u001b[0m \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0/1 \u001b[0m [ \u001b[33m0:00:00\u001b[0m < \u001b[36m-:--:--\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n",
            "\u001b[2KSaving Preprocessed images (ip_adapter)\u001b[35m   0%\u001b[0m \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0/2 \u001b[0m [ \u001b[33m0:00:00\u001b[0m < \u001b[36m-:--:--\u001b[0m , \u001b[31m? it/s\u001b[0m ]\n",
            "\u001b[?25hc='controlnet_ip2p' / []\n",
            "c='controlnet_openpose' / []\n",
            "Saving prompt config to output directory\n",
            "Initialization complete!\n",
            "Generating 1 animations\n",
            "Running generation 1 of 1\n",
            "Generation seed: 168160061448421537\n",
            "len( region_condi_list )=1\n",
            "len( region_list )=1\n",
            "apply_lcm_lora=False\n",
            "controlnet_for_region=False\n",
            "multi_uncond_mode=False\n",
            "unet_batch_size=1\n",
            "prompt_encoder.get_condi_size()=2\n",
            "\u001b[2K\u001b[35m  95%\u001b[0m \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ\u001b[0m \u001b[32m57/60 \u001b[0m [ \u001b[33m0:08:26\u001b[0m < \u001b[36m0:00:27\u001b[0m , \u001b[31m0 it/s\u001b[0m ]"
          ]
        }
      ],
      "source": [
        "#  -W is width -H height. -L length / fps = Duration.  can use -W 512 -H 768\n",
        "!animatediff generate -c config/prompts/prompt_girl.json -W 512 -H 912  -L 20 -C 16 -O 4 -S 4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!animatediff -h"
      ],
      "metadata": {
        "id": "05WAyTgGuNjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!animatediff  refine  -h"
      ],
      "metadata": {
        "id": "6mM0bWQtub8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!animatediff refine --config-path /content/animatediff-cli-prompt-travel/output/2024-01-04T04-02-44-simple-toonyou-jp/prompt.json -t 0.8 -W 1024 -H 1824 -C 8 -O 4 -S 4 /content/animatediff-cli-prompt-travel/output/2024-01-04T04-02-44-simple-toonyou-jp/00-4841095091158654258"
      ],
      "metadata": {
        "id": "e59v4qBrwAG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "CD7EDoZe-Y3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!animatediff stylize  create-config -h"
      ],
      "metadata": {
        "id": "Yiiqf0b_lYJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!animatediff stylize  create-config  /content/animatediff-cli-prompt-travel/GoogleDrive/MyDrive/AI/kamal_ni.mp4 --fps 10"
      ],
      "metadata": {
        "id": "hdegVC_l-ZmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/animatediff-cli-prompt-travel/stylize/2023-12-27T11-36-55-sample-toonyou_beta6/00_controlnet_image/controlnet_openpose/{0.png..119.png} /content/animatediff-cli-prompt-travel/stylize/2023-12-27T11-36-55-sample-toonyou_beta6/00_controlnet_image/animatediff_controlnet"
      ],
      "metadata": {
        "id": "nskLqVC_FteZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!animatediff stylize generate /content/animatediff-cli-prompt-travel/stylize/2023-12-29T12-42-14-sample-toonyou_beta6"
      ],
      "metadata": {
        "id": "-0xnBr5RGEsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm -r /content/animatediff-cli-prompt-travel/stylize/2023-12-27T11-36-55-sample-toonyou_beta6/00_controlnet_image/animatediff_controlnet/controlnet_openpose"
      ],
      "metadata": {
        "id": "AbIjzo2cF6tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os , shutil\n",
        "files_path = \"/content/animatediff-cli-prompt-travel/data/controlnet_image/test/controlnet_openpose\"\n",
        "dest_path= \"/content/animatediff-cli-prompt-travel/data/controlnet_image/test/controlnet_ip2p\"\n",
        "files_dir = os.listdir(files_path)\n",
        "# print(files_dir)\n",
        "for file_name in files_dir:\n",
        "  full_file_path = os.path.join(files_path,file_name)\n",
        "  if os.path.isfile(full_file_path):\n",
        "    shutil.copy(full_file_path,dest_path)"
      ],
      "metadata": {
        "id": "mj9gzfv6LX_D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUCk5Bsj_d--"
      },
      "source": [
        "# Interpolate (Increase FPS) of a Video or Frames."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1mj9lH6Be7ztYtHAr1xUUGT3hRtWJBy_5"
      ],
      "metadata": {
        "id": "VApL-KqO-sGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!7z e RIFE_trained_model_v4.13.2.zip -o/content/animatediff-cli-prompt-travel/data/rife/rife_4.13"
      ],
      "metadata": {
        "id": "skgxsNd5-4RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!animatediff rife interpolate -h"
      ],
      "metadata": {
        "id": "uVRFk9Oy_xtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQOr46fGXvPQ"
      },
      "outputs": [],
      "source": [
        "!animatediff rife interpolate /content/animatediff-cli-prompt-travel/stylize/2023-12-29T12-42-14-sample-toonyou_beta6/2023-12-29T13-32-30_00/00-752654652136 outfile.mp4 --rife-model rife-v4.13 --frame-multiplier 2 --codec h264"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OftZm9XX5vMy"
      },
      "outputs": [],
      "source": [
        "!animatediff refine \"/content/animatediff-cli-prompt-travel/output/2023-12-23T12-47-37-deep_bhai_ii-xxmix9realistic_v40/00-1888206262821907582\" -t 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeZkcXASIyNK"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -framerate 8 -pattern_type glob -i '/content/animatediff-cli-prompt-travel/output/2023-12-23T12-47-37-deep_bhai_ii-xxmix9realistic_v40/00-1888206262821907582/*.png' -c:v libx264 -pix_fmt yuv420p /content/out8.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkCNvTTnFNul"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DTDY1JltjJI"
      },
      "outputs": [],
      "source": [
        "# delete the images from the folder so it can run\n",
        "os.remove(\"data/controlnet_image/test/controlnet_softedge/0000.png\")\n",
        "os.remove(\"data/controlnet_image/test/controlnet_softedge/0016.png\")\n",
        "os.remove(\"data/controlnet_image/test/controlnet_softedge/0032.png\")\n",
        "os.remove(\"data/controlnet_image/test/controlnet_openpose/0000.png\")\n",
        "os.remove(\"data/controlnet_image/test/controlnet_openpose/0016.png\")\n",
        "os.remove(\"data/controlnet_image/test/controlnet_openpose/0032.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwTO7zsguBVp"
      },
      "outputs": [],
      "source": [
        "# take about 4-5 minutes. -W is width -H height. -L length.  can use -W 512 -H 768\n",
        "!animatediff generate -c config/prompts/test001.json -W 256 -H 384 -L 128 -C 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SzoIvKeJm5a"
      },
      "outputs": [],
      "source": [
        "# Copy generated contents to Google drive\n",
        "drive.mount(\"GoogleDrive\")\n",
        "gd_path = \"GoogleDrive/MyDrive/AnimateDiffPromptTravel\"\n",
        "gd_output_dir = gd_path + \"/output\"\n",
        "os.makedirs(gd_output_dir, exist_ok=True)\n",
        "output_dir = \"output\"\n",
        "gc.collect()\n",
        "\n",
        "def get_new_dir(parent_dir):\n",
        "  sub_dirs = []\n",
        "  for path in os.listdir(parent_dir):\n",
        "    dir_path = os.path.join(parent_dir, path)\n",
        "    if os.path.isdir(dir_path):\n",
        "      sub_dirs.append(dir_path)\n",
        "  return max(sub_dirs, key = os.path.getmtime)\n",
        "\n",
        "result_dir = get_new_dir(output_dir)\n",
        "dest_dir = os.path.join(gd_output_dir, os.path.basename(result_dir))\n",
        "shutil.copytree(result_dir, dest_dir, dirs_exist_ok = True)\n",
        "print(f\"üéâ The output files have been copied into {dest_dir}. (in your connected Google Drive) See you there! üéâ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsyEkRQiJm7_"
      },
      "outputs": [],
      "source": [
        "## The END"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrvt6zK1oTRi"
      },
      "source": [
        "Good Luck. If you want to run it locally (needs a Nvidia or AMD GPU), I also video tutorial for them. Subscribe to it today! [Click to subscribe](https://www.youtube.com/@tech-practice9805?sub_confirmation=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvDSGO9wJnA-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bJnV10GE92G"
      },
      "outputs": [],
      "source": [
        "\n",
        "!git clone https://github.com/nihui/rife-ncnn-vulkan.git\n",
        "!cd rife-ncnn-vulkan\n",
        "!git submodule update --init --recursive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video Utils üéû."
      ],
      "metadata": {
        "id": "dPWhnBWz1NaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1tXQOZDHHxeIHvsqnsuwdrFBXjHCh7Gle -O /content/animatediff-cli-prompt-travel/GoogleDrive/MyDrive/AnimateDiffPromptTravel/pahari.mp4"
      ],
      "metadata": {
        "id": "1cE-hQt_24dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i \"/content/animatediff-cli-prompt-travel/GoogleDrive/MyDrive/AI/kamal_ni.mp4\" -vf fps=10  \"/content/animatediff-cli-prompt-travel/data/controlnet_image/test/controlnet_openpose/%05d.png\"\n"
      ],
      "metadata": {
        "id": "seAY_wZ3204-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8995d28d-79af-4472-8b67-98a65ab454b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/animatediff-cli-prompt-travel/GoogleDrive/MyDrive/AI/kamal_ni.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: mp41isom\n",
            "    creation_time   : 2024-01-03T16:28:33.000000Z\n",
            "    title           : 644033594468503\n",
            "  Duration: 00:00:25.10, start: 0.000000, bitrate: 2298 kb/s\n",
            "  Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, unknown/reserved/reserved), 1080x1920 [SAR 1:1 DAR 9:16], 2196 kb/s, 27.07 fps, 27 tbr, 27k tbn, 54 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2024-01-03T16:28:33.000000Z\n",
            "      handler_name    : VideoHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : AVC Coding\n",
            "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 99 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2024-01-03T16:28:33.000000Z\n",
            "      handler_name    : SoundHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to '/content/animatediff-cli-prompt-travel/data/controlnet_image/test/controlnet_openpose/%05d.png':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: mp41isom\n",
            "    title           : 644033594468503\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0(und): Video: png, rgb24(pc, gbr/reserved/reserved, progressive), 1080x1920 [SAR 1:1 DAR 9:16], q=2-31, 200 kb/s, 10 fps, 10 tbn (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2024-01-03T16:28:33.000000Z\n",
            "      handler_name    : VideoHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 png\n",
            "frame=  251 fps= 10 q=-0.0 Lsize=N/A time=00:00:25.10 bitrate=N/A speed=   1x    \n",
            "video:219822kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -framerate {fps} -pattern_type glob -i {frames_path+\"/\"}*.png -c:v libx264 -pix_fmt yuv420p /content/out8.mp4"
      ],
      "metadata": {
        "id": "a5t3NsPs2-P9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2DzQcdrR3Nau",
        "PVvJwnXl-dS0",
        "PIQ6TrKa9w3S"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}